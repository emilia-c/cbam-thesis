{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nescessary libraries\n",
    "import re\n",
    "from collections import Counter\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import functools\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to open data\n",
    "def get_files(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file: \n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# read in: \n",
    "# a) meeting data\n",
    "path_9th_term = 'master_thesis_2025/cbam_meeting_information/data/all_meetings/cleaned_meetings_9term.json'\n",
    "path_10th_term = 'master_thesis_2025/cbam_meeting_information/data/cbam_specific_meetings/test/MEP_MEETINGS_CBAM_01.04.2025.json'\n",
    "\n",
    "meetings_9term = get_files(path_9th_term)\n",
    "meetings_10term = get_files(path_10th_term)\n",
    "\n",
    "# b) transparency registry data\n",
    "path_t_reg = 'master_thesis_2025/cbam_meeting_information/data/transparency_registry/07.2024_registered_orgs_grouped.json'\n",
    "t_reg = get_files(path_t_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Match meeting log with transparency registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of search keywords\n",
    "keywords = [\"CBAM\", \"cbam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import functools\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Helper function to clean text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace and line breaks\n",
    "    return text\n",
    "\n",
    "# Helper function to find similar names or acronyms (fuzzy matching)\n",
    "org_match_cache = {}\n",
    "def find_similar_names(name, org_list):\n",
    "    if name in org_match_cache:\n",
    "        return org_match_cache[name]\n",
    "    \n",
    "    matches = process.extract(name, org_list, scorer=fuzz.partial_ratio, limit=1)\n",
    "    \n",
    "    if matches and matches[0][1] > 90:  # Set matching threshold to 90\n",
    "        org_match_cache[name] = (matches[0][0], matches[0][1])  # Cache the result\n",
    "        return matches[0][0], matches[0][1]\n",
    "    \n",
    "    org_match_cache[name] = None  # Cache the result for non-matches\n",
    "    return None\n",
    "\n",
    "# Function to check if any keyword is present in the text\n",
    "def contains_keywords(text, keywords):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    # Use a case-insensitive search for any of the keywords\n",
    "    pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b', re.IGNORECASE)\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "# Function to analyze individual meeting data\n",
    "def analyze_meeting(entry, org_list, keywords):\n",
    "    qualifying_meetings = []  # Store qualifying meetings\n",
    "    meetings = entry.get(\"meetings\", {})\n",
    "    mep_name = entry.get(\"name\", \"Unknown MEP\")\n",
    "\n",
    "    # Skip processing if meetings is not a dictionary\n",
    "    if isinstance(meetings, str):\n",
    "        return qualifying_meetings\n",
    "\n",
    "    for meeting_id, meeting in meetings.items():\n",
    "        if isinstance(meeting, dict):\n",
    "            reason = clean_text(meeting.get(\"reason\", \"\"))\n",
    "            meeting_with = clean_text(meeting.get(\"meeting_with\", \"\"))\n",
    "            date = meeting.get(\"date\", \"Date not provided\")\n",
    "\n",
    "            # Check for keyword match\n",
    "            reason_has_keywords = contains_keywords(reason, keywords)\n",
    "            meeting_with_has_keywords = contains_keywords(meeting_with, keywords)\n",
    "\n",
    "            # Proceed only if a keyword is found\n",
    "            if reason_has_keywords or meeting_with_has_keywords:\n",
    "                # Check for match in organization list\n",
    "                matched_org = find_similar_names(meeting_with, org_list)\n",
    "\n",
    "                # Prepare output\n",
    "                meeting_entry = {\n",
    "                    \"MEP\": mep_name,\n",
    "                    \"Meeting ID\": meeting_id,\n",
    "                    \"Date\": date,\n",
    "                    \"Meeting With\": meeting_with,\n",
    "                    \"Reason\": reason,\n",
    "                    \"Org Match\": matched_org[0] if matched_org else None,  # Include matched org name\n",
    "                    \"Org Match Similarity\": matched_org[1] if matched_org else None  # Include similarity score\n",
    "                }\n",
    "                qualifying_meetings.append(meeting_entry)\n",
    "\n",
    "    return qualifying_meetings\n",
    "\n",
    "# Function to analyze data with parallel processing\n",
    "def analyze_data(data, org_list, keywords, output_file):\n",
    "    all_qualifying_meetings = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(functools.partial(analyze_meeting, org_list=org_list, keywords=keywords), data))\n",
    "\n",
    "        for qualifying_meetings in results:\n",
    "            all_qualifying_meetings.extend(qualifying_meetings)\n",
    "\n",
    "    # Save to JSON if any qualifying meetings are found\n",
    "    if all_qualifying_meetings:\n",
    "        with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(all_qualifying_meetings, json_file, ensure_ascii=False, indent=4)\n",
    "        print(f\"Qualifying meeting data saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No qualifying meetings found. No file was created.\")\n",
    "\n",
    "# Function to extract organization names and acronyms from JSON data\n",
    "def extract_org_names_and_acronyms(json_data):\n",
    "    org_list = []\n",
    "    for org_name, details in json_data.items():\n",
    "        org_list.append(org_name)  # Add the full name\n",
    "        for detail in details:\n",
    "            acronym = detail.get(\"transparency_no\")\n",
    "            if acronym:\n",
    "                org_list.append(acronym)  # Add the acronym\n",
    "    return org_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_list = extract_org_names_and_acronyms(t_reg)\n",
    "\n",
    "term9_matches = analyze_data(meetings_9term, org_list, \n",
    "                              keywords, output_file='master_thesis_2025/cbam_meeting_information/data/cbam_specific_meetings/ep/cbam_term9_meetings.json')\n",
    "term10_matches = analyze_data(meetings_10term, org_list, \n",
    "                              keywords, output_file='master_thesis_2025/cbam_meeting_information/data/cbam_specific_meetings/ep/cbam_term10_meetings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transform into Excel and add website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meeting_data(json_files, registry_file, output_excel):\n",
    "    # Load transparency registry data\n",
    "    with open(registry_file, 'r', encoding='utf-8') as f:\n",
    "        registry_data = json.load(f)\n",
    "\n",
    "    # Create a lookup for organization details\n",
    "    org_to_details = {\n",
    "        org: {\n",
    "            \"Website\": details[0].get(\"website\", \"N/A\"),\n",
    "            \"Category\": details[0].get(\"registration_category\", \"N/A\"),\n",
    "            \"Members\": details[0].get(\"members\", \"N/A\"),\n",
    "            \"Budget\": details[0].get(\"total_budget\", \"N/A\"),\n",
    "            \"Mission\": details[0].get(\"mission\", \"N/A\"),\n",
    "        }\n",
    "        for org, details in registry_data.items()\n",
    "    }\n",
    "\n",
    "    # Combine data from all JSON files\n",
    "    all_meetings = []\n",
    "    for file in json_files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            all_meetings.extend(json.load(f))\n",
    "\n",
    "    # Create a dictionary to store aggregated data\n",
    "    org_data = {}\n",
    "    for meeting in all_meetings:\n",
    "        org_name = meeting[\"Org Match\"]\n",
    "        if not org_name:\n",
    "            continue  # Skip if there's no org match\n",
    "\n",
    "        if org_name not in org_data:\n",
    "            org_details = org_to_details.get(org_name, {})\n",
    "            org_data[org_name] = {\n",
    "                \"Organization Name\": org_name,\n",
    "                \"Website\": org_details.get(\"Website\", \"N/A\"),\n",
    "                \"Category\": org_details.get(\"Category\", \"N/A\"),\n",
    "                \"Members\": org_details.get(\"Members\", \"N/A\"),\n",
    "                \"Budget\": org_details.get(\"Budget\", \"N/A\"),\n",
    "                \"Mission\": org_details.get(\"Mission\", \"N/A\"),\n",
    "                \"Reasons for Meeting\": set(),\n",
    "                \"MEPs Met With\": set()\n",
    "            }\n",
    "\n",
    "        # Add meeting reasons and MEP names as strings to sets\n",
    "        org_data[org_name][\"Reasons for Meeting\"].add(str(meeting[\"Reason\"]))\n",
    "        org_data[org_name][\"MEPs Met With\"].add(str(meeting[\"MEP\"]))\n",
    "\n",
    "    # Prepare data for the Excel file\n",
    "    final_data = []\n",
    "    for org, details in org_data.items():\n",
    "        final_data.append({\n",
    "            \"Organization Name\": details[\"Organization Name\"],\n",
    "            \"Website\": details[\"Website\"],\n",
    "            \"Category\": details[\"Category\"],\n",
    "            \"Members\": details[\"Members\"],\n",
    "            \"Budget\": details[\"Budget\"],\n",
    "            \"Mission\": details[\"Mission\"],\n",
    "            \"Reasons for Meeting\": \"; \".join(details[\"Reasons for Meeting\"]),\n",
    "            \"MEPs Met With\": \"; \".join(details[\"MEPs Met With\"])\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame and save to Excel\n",
    "    df = pd.DataFrame(final_data)\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Data saved to {output_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output Excel file\n",
    "output_excel = \"master_thesis_2025/cbam_meeting_information/data/cbam_specific_meetings/ep/aggregated_cbam_meeting_data.xlsx\"\n",
    "\n",
    "json_files = ['master_thesis_2025/cbam_meeting_information/data/cbam_specific_meetings/ep/cbam_term9_meetings.json', \n",
    "              'master_thesis_2025/cbam_meeting_information/data/cbam_specific_meetings/ep/cbam_term10_meetings.json']\n",
    "registry_file = 'master_thesis_2025/cbam_meeting_information/data/transparency_registry/07.2024_registered_orgs_grouped.json'\n",
    "\n",
    "# run the extraction and save to Excel\n",
    "extract_meeting_data(json_files, registry_file, output_excel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scicomp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
